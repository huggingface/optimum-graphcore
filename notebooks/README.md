# Notebooks

| Notebook     |      Description      | |
|:----------|:-------------|:-------------|
| [Introduction to Optimum Graphcore](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/introduction_to_optimum_graphcore.ipynb) |  Introduce Optimum-Graphcore with a BERT fine-tuning example. | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Fintroduction_to_optimum_graphcore.ipynb) |
| [Train your language model](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modelling_from_scratch.ipynb) | Show how to train a model for causal or masked language modelling from scratch. | |
| [How to fine-tune a model on text classification](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/text_classification.ipynb) | Show how to preprocess the data and fine-tune a pretrained model on any GLUE task. | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Ftext_classification.ipynb) |
| [How to fine-tune a model on language modeling](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modeling.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task. | |
| [How to fine-tune a model on token classification](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/token_classification.ipynb) | Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS). | |
| [How to fine-tune a model on question answering](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/question_answering.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on SQUAD. |
| [How to fine-tune a model on translation](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/translation.ipynb) | Show how to preprocess the data and fine-tune a pretrained model on WMT. | |
| [How to fine-tune a model on summarization](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/summarization.ipynb) | Show how to preprocess the data and fine-tune a pretrained model on XSUM. | | 
| [How to fine-tune a model on audio classification](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/audio_classification.ipynb)| Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword Spotting | |
| [How to fine-tune a model on image classfication](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/image_classification.ipynb) |  Show how to preprocess the data and fine-tune a pretrained model on image classification. | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fget-started%2Fwalkthrough.ipynb) | 
| [wav2vec 2.0 Fine-Tuning on IPU](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-fine-tuning-checkpoint.ipynb) |  How to fine-tune a pre-trained wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system.| |
| [wav2vec 2.0 Inference on IPU](https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-inference-checkpoint.ipynb) |  How to run inference on the wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system.| |
