{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion Text-guided In-painting on IPU\n",
    "\n",
    "This notebook demonstrates how a stable diffusion inference pipeline can be run on Graphcore IPUs.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* An enabled Poplar SDK environment (or Paperspace account with access to the PyTorch IPU runtime)\n",
    "* Additional dependencies installable via pip (done below)\n",
    "* Access to the pretrained Stable-Diffusion-v1-5 checkpoint (done below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for machine size and cache directories can be configured through environment variables or directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod16\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the pretrained Stable-Diffusion-v1-5 checkpoint, we must first authenticate to the Hugging Face Hub. Begin by creating a read access token on the [Hugging Face website](https://huggingface.co/settings/tokens) (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your read token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so already, you will need to accept the User License on the [model page](https://huggingface.co/runwayml/stable-diffusion-inpainting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to import and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ipu_models import IPUStableDiffusionInpaintPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = IPUStableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\", \n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    ipu_config={\n",
    "        \"executable_cache_dir\": executable_cache_dir,\n",
    "    }\n",
    ")\n",
    "pipe.enable_attention_slicing(slice_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = os.getenv(\"STABLE_DIFFUSION_INPAINT_DEFAULT_WIDTH\", default=512)\n",
    "image_height = os.getenv(\"STABLE_DIFFUSION_INPAINT_DEFAULT_HEIGHT\", default=512)\n",
    "image_dimensions = (image_width, image_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a dummy generation step to trigger the one-time compilation process. This should take on the order of 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "pipe(\"apple\", \n",
    "     image=Image.new(\"RGB\", image_dimensions), \n",
    "     mask_image=Image.new(\"RGB\", image_dimensions, (255, 255, 255)), \n",
    "     guidance_scale=7.5\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess and visualize a context image which will be used to initialize the latents passed to the UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
    "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = download_image(img_url).resize(image_dimensions)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = download_image(mask_url).resize(image_dimensions)\n",
    "mask_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find an example prompt. We encourage you to try your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a mecha robot sitting on a bench\"\n",
    "pipe(prompt, image=image, mask_image=mask_image, guidance_scale=7.5).images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk3_1145",
   "language": "python",
   "name": "sdk3_1145"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb566221b6fb66eb17be1e54d5bad447b448f6085074d60633cde4e94a153eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
