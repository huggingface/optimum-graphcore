{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Text-to-Image Generation on IPUs\n",
    "\n",
    "This notebook demonstrates how a Stable Diffusion inference pipeline can be run on Graphcore IPUs. Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images defined by text input. \n",
    "\n",
    "We are using the pre-trained [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) checkpoint.\n",
    "\n",
    "![Text to image on stable diffusion](sample_images/text_to_image.png)\n",
    "\n",
    "\n",
    "|  Domain | Tasks | Model | Datasets | Workflow |   Number of IPUs   | Execution time |\n",
    "|---------|-------|-------|----------|----------|--------------|--------------|\n",
    "|      |    | stable-diffusion-v1-5 | | Inference | recommended: 16XX (min: 4X) | 20Xmn (X1h20mn)   |\n",
    "\n",
    "[![Run on Gradient](../images/gradient-badge.svg)](https://ipu.dev/3iyhJkk)  [![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)\n",
    "\n",
    "\n",
    "## Environment setup\n",
    "\n",
    "The best way to run this demo is on Paperspace Gradient's cloud IPUs because everything is already set up for you. To run the demo using other IPU hardware, you need to have the Poplar SDK enabled. Refer to the [getting started guide](https://docs.graphcore.ai/en/latest/getting-started.html#getting-started) for your system for details on how to enable the Poplar SDK. \n",
    "\n",
    "Install the additional dependencies, which includes the [ðŸ¤— Optimum Graphcore library](https://github.com/huggingface/optimum-graphcore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this Jupyter notebook on a remote IPU machine:\n",
    "\n",
    "1. Enable a Poplar SDK environment (see the [getting started guide](https://docs.graphcore.ai/en/latest/getting-started.html) \n",
    "for your IPU system) and install the required packages with `python -m pip install -r requirements.txt`.\n",
    "\n",
    "2. In the same environment, install the Jupyter notebook server: `python -m pip install notebook`.\n",
    "\n",
    "3. Launch a Jupyter Server on a specific port: `jupyter-notebook --no-browser --port <port number>`.\n",
    "\n",
    "4. Connect via SSH to your remote machine, forwarding your chosen port: `ssh -NL <port number>:localhost:<port number> <your username>@<remote machine>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for the virtual IPU Pod size and the cache directories can be configured through environment variables or directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod4\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/stablediffusion_to-image\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the pre-trained Stable-Diffusion-v1-5 checkpoint, we must first authenticate to the Hugging Face Hub:\n",
    "1. Create a read access token on the [ðŸ¤— website]((https://huggingface.co/settings/tokens)). [Sign up to ðŸ¤—](https://huggingface.co/join) if you haven't already.\n",
    "2. Execute the following cell and input your username and token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so already, you will need to accept the User License on the [model page](https://huggingface.co/runwayml/stable-diffusion-v1-5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to import and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from optimum.graphcore.diffusers import get_default_ipu_configs, INFERENCE_ENGINES_TO_MODEL_NAMES, IPUStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"stable-diffusion-v1-5\"  # maps to \"runwayml/stable-diffusion-v1-5\"\n",
    "model_name = INFERENCE_ENGINES_TO_MODEL_NAMES[engine]\n",
    "image_width = os.getenv(\"STABLE_DIFFUSION_TXT2IMG_DEFAULT_WIDTH\", default=512)\n",
    "image_height = os.getenv(\"STABLE_DIFFUSION_TXT2IMG_DEFAULT_HEIGHT\", default=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_ipu_config, text_encoder_ipu_config, vae_ipu_config, safety_checker_ipu_config = \\\n",
    "get_default_ipu_configs(\n",
    "    engine=engine, width=image_width, height=image_height, pod_type=pod_type, \n",
    "    executable_cache_dir=executable_cache_dir \n",
    ")\n",
    "pipe = IPUStableDiffusionPipeline.from_pretrained(\n",
    "    model_name,\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    unet_ipu_config=unet_ipu_config,\n",
    "    text_encoder_ipu_config=text_encoder_ipu_config,\n",
    "    vae_ipu_config=vae_ipu_config,\n",
    "    safety_checker_ipu_config=safety_checker_ipu_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a dummy generation step to trigger the one-time compilation process. This should take on the order of 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe(\"apple\", height=image_height, width=image_width, guidance_scale=7.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three cells below contain some example text prompts. We encourage you to try your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a shiba inu in a zen garden, acrylic painting\"\n",
    "pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"the living room of a cozy wooden house with a fireplace\"\n",
    "out = pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5)\n",
    "out.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(9, 9)\n",
    "ax.imshow(out.images[0])\n",
    "\n",
    "ax.set_title(f\"Prompt: {prompt}\")\n",
    "ax.axis(\"off\")\n",
    "fig.savefig(\"sample_images/text_to_image.png\", dpi=150)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release IPUs in use\n",
    "\n",
    "The IPython kernel has a lock on the IPUs used in running the model, preventing other users from using them. For example, if you wish to use other notebooks after running this notebook, it may be necessary to manually run the cell below to release the IPUs you have been using. This will happen by default if you use the `Run All` notebook option. More information can be found in the notebook on [managing IPU resources](https://github.com/gradient-ai/Graphcore-HuggingFace/blob/main/useful-tips/managing_ipu_resources.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.detach_from_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Check out the full list of [Optimum Graphcore notebooks](https://github.com/huggingface/optimum-graphcore/tree/main/notebooks) to get a feel for how IPUs perform on other tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb566221b6fb66eb17be1e54d5bad447b448f6085074d60633cde4e94a153eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
