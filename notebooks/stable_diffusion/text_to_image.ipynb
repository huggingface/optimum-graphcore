{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion Text-to-Image Generation on IPU\n",
    "\n",
    "This notebook demonstrates how a stable diffusion inference pipeline can be run on Graphcore IPUs.\n",
    "\n",
    "![Text to image on stable diffusion](sample_images/text_to_image.png)\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* An enabled Poplar SDK environment (or Paperspace account with access to the PyTorch IPU runtime)\n",
    "* Additional dependencies installable via pip (done below)\n",
    "* Access to the pretrained Stable-Diffusion-v1-5 checkpoint (done below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for the virtual IPU Pod size and the cache directories can be configured through environment variables or directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod4\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/stablediffusion_to-image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the pretrained Stable-Diffusion-v1-5 checkpoint, we must first authenticate to the Hugging Face Hub. Begin by creating a read access token on the [Hugging Face website](https://huggingface.co/settings/tokens) (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your read token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so already, you will need to accept the User License on the [model page](https://huggingface.co/runwayml/stable-diffusion-v1-5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to import and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ipu_models import get_default_ipu_configs, INFERENCE_ENGINES_TO_MODEL_NAMES, IPUStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"stable-diffusion-v1-5\"  # maps to \"runwayml/stable-diffusion-v1-5\"\n",
    "model_name = INFERENCE_ENGINES_TO_MODEL_NAMES[engine]\n",
    "image_width = os.getenv(\"STABLE_DIFFUSION_TXT2IMG_DEFAULT_WIDTH\", default=512)\n",
    "image_height = os.getenv(\"STABLE_DIFFUSION_TXT2IMG_DEFAULT_HEIGHT\", default=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_ipu_config, text_encoder_ipu_config, vae_ipu_config, safety_checker_ipu_config = \\\n",
    "get_default_ipu_configs(\n",
    "    engine=engine, width=image_width, height=image_height, pod_type=pod_type, \n",
    "    executable_cache_dir=executable_cache_dir \n",
    ")\n",
    "pipe = IPUStableDiffusionPipeline.from_pretrained(\n",
    "    model_name,\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    unet_ipu_config=unet_ipu_config,\n",
    "    text_encoder_ipu_config=text_encoder_ipu_config,\n",
    "    vae_ipu_config=vae_ipu_config,\n",
    "    safety_checker_ipu_config=safety_checker_ipu_config\n",
    ")\n",
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a dummy generation step to trigger the one-time compilation process. This should take on the order of 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe(\"apple\", height=image_height, width=image_width, guidance_scale=7.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find some example prompts. We encourage you to try your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a shiba inu in a zen garden, acrylic painting\"\n",
    "pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"the living room of a cozy wooden house with a fireplace\"\n",
    "out = pipe(prompt, height=image_height, width=image_width, guidance_scale=7.5)\n",
    "out.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(9, 9)\n",
    "ax.imshow(out.images[0])\n",
    "\n",
    "ax.set_title(f\"Prompt: {prompt}\")\n",
    "ax.axis(\"off\")\n",
    "fig.savefig(\"sample_images/text_to_image.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Release IPUs in use\n",
    "\n",
    "The IPython kernel has a lock on the IPUs used in running the model, preventing other users from using them. For example, if you wish to use other notebooks after working your way through this one, it may be necessary to manually run the below cell to release IPUs from use. This will happen by default if using the `Run All` option. More information on the topic can be found at [Managing IPU Resources](https://github.com/gradient-ai/Graphcore-HuggingFace/blob/main/useful-tips/managing_ipu_resources.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.detach_from_device()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb566221b6fb66eb17be1e54d5bad447b448f6085074d60633cde4e94a153eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
