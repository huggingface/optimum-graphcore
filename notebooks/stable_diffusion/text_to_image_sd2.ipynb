{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion 2 Text-to-Image Generation on IPU\n",
    "\n",
    "This notebook demonstrates how a stable diffusion inference pipeline can be run on Graphcore IPUs.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* An enabled Poplar SDK environment (or Paperspace account with access to the PyTorch IPU runtime)\n",
    "* Additional dependencies installable via pip (done below)\n",
    "* Access to the pretrained Stable-Diffusion-v2 checkpoint (done below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for machine size and cache directories can be configured through environment variables or directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", \"pod16\")\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/exe_cache/\") + \"/stablediffusion2_text2img\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the pretrained Stable-Diffusion-v2 checkpoint, we must first authenticate to the Hugging Face Hub. Begin by creating a read access token on the [Hugging Face website](https://huggingface.co/settings/tokens) (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your read token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so already, you will need to accept the User License on the [model page](https://huggingface.co/stabilityai/stable-diffusion-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to import and run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "from ipu_models import IPUStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = IPUStableDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2\",\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    ipu_config={\n",
    "        \"matmul_proportion\": [0.06, 0.1, 0.1, 0.1],\n",
    "        \"executable_cache_dir\": executable_cache_dir,\n",
    "    },\n",
    "    requires_safety_checker=False\n",
    ")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = os.getenv(\"STABLE_DIFFUSION_2_TXT2IMG_DEFAULT_WIDTH\", default=768)\n",
    "image_height = os.getenv(\"STABLE_DIFFUSION_2_TXT2IMG_DEFAULT_HEIGHT\", default=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a dummy generation step to trigger the one-time compilation process. This should take on the order of 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe(\"apple\", height=image_height, width=image_width, num_inference_steps=25, guidance_scale=9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will find some example prompts. We encourage you to try your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a shiba inu in a zen garden, acrylic painting\"\n",
    "pipe(prompt, height=image_height, width=image_width, num_inference_steps=25, guidance_scale=9).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\"\n",
    "pipe(prompt, height=image_height, width=image_width, num_inference_steps=25, guidance_scale=9).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"the living room of a cozy wooden house with a fireplace\"\n",
    "pipe(prompt, height=image_height, width=image_width, num_inference_steps=25, guidance_scale=9).images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk3_1145",
   "language": "python",
   "name": "sdk3_1145"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb566221b6fb66eb17be1e54d5bad447b448f6085074d60633cde4e94a153eec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
