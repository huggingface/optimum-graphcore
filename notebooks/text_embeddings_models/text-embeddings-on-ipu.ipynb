{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f588db-977d-487c-aae5-1f6a76ff5376",
   "metadata": {},
   "source": [
    "# General-purpose text embeddings on the IPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dcd25-64d4-4380-b401-3478d41074a7",
   "metadata": {},
   "source": [
    "This notebook describes how to use supported embeddings models to generate SOTA text embeddings on the IPU. You can use the:\n",
    "* [E5 model](https://arxiv.org/pdf/2212.03533.pdf) (Emb**E**ddings from bidir**E**ctional **E**ncoder r**E**presentations) to generate text embeddings on the IPU.\n",
    "* [Sentence Transformers MPNet Base V2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) An embeddings model based on the MPNet base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a0eeb-dc30-49f9-9340-93881810fb43",
   "metadata": {},
   "source": [
    "Here, we demonstrate how to use the fine-tuned E5-large model for inference, and then show how to use the embeddings for a semantic search application example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d591cc4-38ca-47ae-a52f-165b04deb0a8",
   "metadata": {},
   "source": [
    "First, install the requirements for running this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cef646-7eb2-4c12-9b40-fc82f3116d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a8017-830e-45fd-9a14-76661bd61424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install sentence-transformers\n",
    "! pip install --find-links https://download.pytorch.org/whl/cpu/torch_stable.html torch==1.13.1+cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caff0d-c9dd-426b-a62f-08e53ff1c201",
   "metadata": {},
   "source": [
    "Next, import the required modules for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb86be2-6ba9-48dc-a948-6009dcf617e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import poptorch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c52bb-63fc-4c3d-9ee0-40ae4a1c02f5",
   "metadata": {},
   "source": [
    "We need to instantiate some global parameters that will be used to run the model. Here, we define the model name (the checkpoint which will be downloaded from the Hugging Face Hub) and the effective batch size. \n",
    "\n",
    "The **micro batch size** (number of batches to process in parallel) is set to a smaller value of 2 due to its greater effect on device memory. \n",
    "\n",
    "We use on-IPU loops (**device iterations**) which iterate over a number of batches sequentially (where the iteration takes place on-device in one dataloader call), to extend the batch size for more throughput benefit (this is more efficient than loading smaller batches on the host a large number of times). \n",
    "\n",
    "Data parallelism is controlled by the **replication factor**, i.e. how many devices the batch sizes are replicated over. This value is set to `None` by default as it will be automatically determined by the `pod_type` of the machine being used. By default, the model itself requires 1 IPU to run, and if running on a IPU POD4 (4 IPU) machine, the replication factor is set to 4. Similarly, if running on an IPU POD16, it is set to 16. This can be overidden with a different value if needed, i.e., if `replication_factor=N` the model will be replicated over `N` IPUs as long as `N * n_ipu (number of IPUs a single instance of the model uses) <= total available IPUs`.\n",
    "\n",
    "The total effective batch size for inference is calculated by:\n",
    "```\n",
    "effective_batch_size = replication_factor * device_iterations * micro_batch_size\n",
    "```\n",
    "\n",
    "The model itself, through model pipelining, can also be run over **2** or **4** IPUs (by setting `model_ipu` to 2 or 4), in which case the replication factor will be adjusted accordingly. The reason we might want to spread the model over more IPUs is to reduce the memory consumption of the model over a single machine (e.g., with 4 IPUs, we compute far fewer layers per IPU, while with 1 IPU, all model layers are on a single IPU) allowing for higher batch sizes to be used. This is particularly beneficial on an IPU POD16 machine, as the 4-IPU pipelined version of the model can be run at a higher effective batch size (with higher micro batch size) and achieve even higher overall batched throughput.\n",
    "\n",
    "The maximum sequence length for the tokenizer is set to 512, as this is the default maximum positional embeddings value based on the bidirectional encoder configuration for the pre-trained checkpoint.\n",
    "\n",
    "The checkpoint (`model_name`) can be directly modified to use one of the [unsupervised](https://github.com/microsoft/unilm/tree/master/e5#english-pre-trained-models) checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e503c3df-45ce-4613-ac7c-3b38a48ed40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"\")\n",
    "\n",
    "model_name = 'sentence-transformers/all-mpnet-base-v2' #'intfloat/e5-large' #'intfloat/e5-small'\n",
    "n_ipu = os.getenv(\"NUM_AVAILABLE_IPU\", 4)\n",
    "\n",
    "model_ipu = 1\n",
    "micro_batch_size = 2\n",
    "device_iterations = 256\n",
    "replication_factor = None\n",
    "\n",
    "max_seq_len = 512\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315eb4c-84ea-49a5-a7d8-635248e22044",
   "metadata": {},
   "source": [
    "Next, define the `transformers` `AutoTokenizer` to instantiate a vocabulary tokenizer for our input text, for the task we define an maximum input sequence length of 512 and pad each sequence to the maximum sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b32b404-fe23-4c10-a95e-433505a210b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BatchEncoding\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def transform_func(example) -> BatchEncoding:\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        max_length=max_seq_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf200e-2375-4d58-aa41-d64daf8017ad",
   "metadata": {},
   "source": [
    "The model config needs to be instantiated for the E5 model. E5 uses a bidirectional encoder, essentially the encoder stage of a BERT model, to generate the trained embeddings. The config will define the architecture of the model, such as the number of encoder layers and size of the hidden dimension within the model.\n",
    "\n",
    "We define some IPU specific configurations to get the most out of the model, the `get_ipu_config` function will set up the IPU config according to the model config, taking into consideration the defined number of IPUs for model parallelism, the number of IPUs available and batching configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e140bc-d2e2-4da3-a53d-3532094554fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdata/arsalanu/popsdk_venvs/3.2.1+1370/3.2.1+1370_poptorch/lib/python3.8/site-packages/optimum/graphcore/ipu_configuration.py:403: UserWarning: The \"enable_half_first_order_momentum\" parameter is deprecated\n",
      "  warnings.warn('The \"enable_half_first_order_momentum\" parameter is deprecated')\n"
     ]
    }
   ],
   "source": [
    "from config import get_ipu_config\n",
    "from transformers import AutoConfig\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "ipu_config = get_ipu_config(\n",
    "    model_config, n_ipu, model_ipu, device_iterations, replication_factor, random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b40f13-ccc2-423f-b2f3-b23867dae7d7",
   "metadata": {},
   "source": [
    "To run the model on the IPU, we use a simple wrapper class for embeddings models called `IPUEmbeddingsModel`. This loads the embeddings model and performs pooling and normalisation on the output. Lets write this method out here to see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9d71a3-7b02-4a0e-8056-aa34f8777d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from typing import Optional, List\n",
    "\n",
    "from transformers import AutoModel\n",
    "from optimum.graphcore.modeling_utils import to_pipelined\n",
    "\n",
    "logger = logging.getLogger(\"e5\")\n",
    "\n",
    "class IPUEmbeddingsModel(torch.nn.Module):\n",
    "    def __init__(self, model_name, model_config, ipu_config, fp16=True):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name, config=model_config)\n",
    "        print(self.model)\n",
    "        self.model = to_pipelined(self.model, ipu_config)\n",
    "        self.model = self.model.parallelize()\n",
    "        if fp16: self.model = self.model.half()\n",
    "    \n",
    "    def pool(\n",
    "        self, \n",
    "        last_hidden_states: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        pool_type: str\n",
    "        ) -> torch.Tensor:\n",
    "             \n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    \n",
    "        if pool_type == \"avg\":\n",
    "            emb = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        elif pool_type == \"cls\":\n",
    "            emb = last_hidden[:, 0]\n",
    "        else:\n",
    "            raise ValueError(f\"pool_type {pool_type} not supported\")\n",
    "\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, pool_type: str ='avg', **kwargs) -> torch.Tensor:\n",
    "\n",
    "        outputs = self.model(**kwargs)\n",
    "        embeds = self.pool(outputs.last_hidden_state, kwargs[\"attention_mask\"], pool_type=pool_type)\n",
    "        embeds = torch.nn.functional.normalize(embeds, p=2, dim=-1)\n",
    "\n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46219b-b495-474c-8392-9c174f4a8082",
   "metadata": {},
   "source": [
    "The `IPUEmbeddingsModel` class instantiates the Transformers model from the checkpoint (`model_name`) and applies IPU parallelisation to it over the defined number of IPUs, applying some optimisations at the same time. Then, it can perform a forward pass using any supported model along with the pooling and normalisation required for embeddings models. \n",
    "\n",
    "To run the model on the IPU, the IPU config needs to be first converted to an `IPUOptions` class and passed alongside the model to the `poptorch.inferenceModel` wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8005d4c-80e1-4f21-96db-0293d9868de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNetModel(\n",
      "  (embeddings): MPNetEmbeddings(\n",
      "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): MPNetEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): MPNetLayer(\n",
      "        (attention): MPNetAttention(\n",
      "          (attn): MPNetSelfAttention(\n",
      "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (intermediate): MPNetIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): MPNetOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (relative_attention_bias): Embedding(32, 12)\n",
      "  )\n",
      "  (pooler): MPNetPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import modeling_bert, modeling_mpnet\n",
    "\n",
    "model = IPUEmbeddingsModel(\n",
    "    model_name = model_name,\n",
    "    model_config = model_config,\n",
    "    ipu_config = ipu_config\n",
    ")\n",
    "\n",
    "ipu_options = ipu_config.to_options(for_inference=True)\n",
    "model = poptorch.inferenceModel(model, ipu_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec397618-4bfa-45b9-bbc1-dc3138dc725d",
   "metadata": {},
   "source": [
    "Lets load a dataset to try out the model. Using the Hugging Face `datasets` library we can load a pre-existing dataset from the Hugging Face Hub. In this case, lets use the `rotten_tomatoes` film review dataset. Later in the notebook, we will use this dataset to perform create a basic semantic search functionality.\n",
    "\n",
    "The dataset first needs to be tokenized, we can use the `map()` method to tokenize each of the inputs of the dataset.\n",
    "\n",
    "Finally, we can convert the Hugging Face Arrow format dataset to a Pytorch ready dataset with `set_format` which converts the tokenized inputs into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591e6055-2e37-41b0-891b-dda98e449513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/arsalanu/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f13397473f345dfa415633e79094368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/arsalanu/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-264068b7cd1b9008.arrow\n",
      "Loading cached processed dataset at /home/arsalanu/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46/cache-e00562798c9ffcfe.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n",
    "tokenized_dataset = dataset.map(transform_func, batched=True)\n",
    "\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d4c56-6272-4344-98cc-bd725b19a7ef",
   "metadata": {},
   "source": [
    "The tokenized dataset is passed to the [`poptorch.Dataloader`](https://docs.graphcore.ai/projects/poptorch-user-guide/en/latest/batching.html) to create a IPU-ready batched dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aadfc38-12fd-4b70-9466-478025b33454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator as data_collator\n",
    "\n",
    "poptorch_dataloader = poptorch.DataLoader(\n",
    "    ipu_options,\n",
    "    tokenized_dataset['train'],\n",
    "    batch_size=micro_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a5e6a-e4d4-4d8b-b3a7-25a59047f674",
   "metadata": {},
   "source": [
    "We define a simple `infer()` function which will perform inference iteratively on each batch and return the concatenated list of embeddings for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94eda93-6954-4cd8-965d-594795782b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dataloader):\n",
    "    encoded_embeds = []\n",
    "    with torch.no_grad():\n",
    "        for batch_dict in tqdm(dataloader, desc='encoding'):\n",
    "            lat = time.time()\n",
    "            outputs = model(**batch_dict)\n",
    "            lat = time.time() - lat\n",
    "            \n",
    "            encoded_embeds.append(outputs)\n",
    "            print(f\"batch len: {len(batch_dict['input_ids'])} | batch latency: {lat}s | per_sample: {lat/len(batch_dict['input_ids'])}s | throughput: {len(batch_dict['input_ids'])/lat} samples/s\")\n",
    "    \n",
    "    return torch.cat(encoded_embeds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c2f53-0aca-4e89-8db8-09e9a1795061",
   "metadata": {},
   "source": [
    "To run the model, first we pass an arbitrary call to the model using the first batch to ensure we have compiled the model executable (or loaded the already compiled executable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77fa8c3-e477-4ebe-9dcd-a35730f4b81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph compilation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:21<00:00]\n",
      "WARNING: The compile time engine option debug.branchRecordTile is set to \"5887\" when creating the Engine. (At compile-tile it was set to 1471)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile time: 156.66175532341003\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "c = time.time()\n",
    "model(**next(iter(poptorch_dataloader)))\n",
    "print(f\"Compile time: {time.time() - c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacec9c0-1a24-4db7-938b-34fd28864a2c",
   "metadata": {},
   "source": [
    "Then, simply call the `infer` function to generate embeddings for the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9d4bb7-cfec-4251-8fe4-1d51c9873b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a257fd830f0246c08d50e73845360d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "encoding:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch len: 2048 | batch latency: 0.9031727313995361s | per_sample: 0.00044100231025367975s | throughput: 2267.5618171359815 samples/s\n",
      "batch len: 2048 | batch latency: 0.8890142440795898s | per_sample: 0.00043408898636698723s | throughput: 2303.675125161044 samples/s\n",
      "batch len: 2048 | batch latency: 0.888725996017456s | per_sample: 0.00043394824024289846s | throughput: 2304.4222957103348 samples/s\n",
      "batch len: 2048 | batch latency: 0.8889319896697998s | per_sample: 0.00043404882308095694s | throughput: 2303.8882881926033 samples/s\n"
     ]
    }
   ],
   "source": [
    "runtime = time.time()\n",
    "embeddings = infer(model, poptorch_dataloader)\n",
    "runtime = time.time() - runtime\n",
    "\n",
    "model.detachFromDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903931f0-bb08-472a-a33d-6ff29b773a9e",
   "metadata": {},
   "source": [
    "Lets print out one of the results, and the total IPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b170bf1a-1db6-4d8b-9099-479eb616bb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPU runtime: 3.665679454803467\n",
      " First embedding: tensor([ 1.4702e-02, -7.2594e-03,  1.1894e-02, -1.5137e-02,  5.8746e-03,\n",
      "        -4.0703e-03, -2.7069e-02,  8.7814e-03,  6.8398e-03,  1.9318e-02,\n",
      "        -1.7578e-02,  1.9852e-02, -6.7322e-02,  3.0914e-02,  8.8379e-02,\n",
      "        -6.8542e-02,  2.5558e-02, -1.6830e-02,  2.5696e-02, -2.9953e-02,\n",
      "         1.6052e-02, -2.5848e-02, -8.2245e-03, -1.3725e-02, -3.2379e-02,\n",
      "        -4.5380e-02,  4.3091e-02,  5.2246e-02,  4.3182e-02, -2.6886e-02,\n",
      "        -7.5562e-02, -7.0877e-03,  1.4450e-02,  5.1231e-03,  1.8477e-06,\n",
      "        -4.3365e-02,  9.6817e-03, -3.0594e-02, -5.8365e-03, -4.5471e-02,\n",
      "        -7.0129e-02, -2.9659e-04, -4.1534e-02, -2.8900e-02,  3.7781e-02,\n",
      "        -6.2042e-02, -1.4290e-02,  2.6337e-02, -5.9814e-02, -5.4893e-03,\n",
      "         1.9455e-02, -5.2948e-02, -1.1711e-02, -2.5604e-02,  3.4790e-02,\n",
      "        -1.0109e-02, -2.0233e-02,  5.6458e-02, -7.1096e-04,  1.4687e-02,\n",
      "        -3.5126e-02,  2.8824e-02, -2.4933e-02,  1.7426e-02,  9.2468e-02,\n",
      "        -3.3264e-03, -8.3374e-02,  8.8013e-02, -7.1030e-03, -9.4938e-04,\n",
      "        -3.4485e-02, -1.1795e-02,  2.8687e-02, -1.1002e-02,  3.5675e-02,\n",
      "         3.7872e-02,  8.2169e-03,  8.4106e-02,  1.4473e-02, -4.9652e-02,\n",
      "        -8.5266e-02, -5.6114e-03,  2.6123e-02, -1.7990e-02,  2.4872e-02,\n",
      "         7.9712e-02,  1.3031e-02, -1.6434e-02,  1.1566e-02,  4.3671e-02,\n",
      "         2.3163e-02, -1.6357e-02, -1.2627e-02, -1.2650e-02, -2.6077e-02,\n",
      "        -2.6817e-03,  1.1917e-02,  2.6123e-02,  2.0493e-02, -2.5330e-02,\n",
      "        -2.9358e-02, -9.0361e-04,  1.1063e-03,  4.6387e-02, -3.8055e-02,\n",
      "         3.1738e-02, -2.2995e-02, -1.0498e-01,  1.5137e-02,  6.1737e-02,\n",
      "        -3.8635e-02,  1.4656e-02, -6.1829e-02,  1.7410e-02,  4.9835e-02,\n",
      "        -3.1708e-02, -1.3832e-02,  2.8595e-02,  2.3270e-02,  7.1106e-03,\n",
      "        -3.0884e-02, -2.1210e-03, -7.8735e-03, -5.6915e-02, -4.2908e-02,\n",
      "         2.8915e-03,  4.2114e-03, -2.2736e-03, -7.6256e-03, -4.1008e-03,\n",
      "        -3.1829e-04,  9.0561e-03,  3.7292e-02,  3.2196e-02,  2.7046e-03,\n",
      "        -6.6566e-03, -9.3918e-03, -4.1275e-03,  9.7107e-02, -1.4175e-02,\n",
      "        -1.5554e-03,  4.4037e-02,  3.3855e-03, -5.3223e-02,  1.3039e-02,\n",
      "        -3.7174e-03,  2.3880e-02,  3.1799e-02, -2.5375e-02,  1.7105e-02,\n",
      "         9.9121e-02, -2.9358e-02, -9.8572e-03, -1.3781e-03, -2.8091e-02,\n",
      "        -4.6310e-03, -5.6335e-02, -7.4036e-02, -2.9087e-03,  1.5701e-02,\n",
      "        -1.2550e-02, -1.6159e-02, -5.5328e-02,  1.8295e-02, -5.9357e-02,\n",
      "        -4.3060e-02,  3.6072e-02, -2.6840e-02,  8.6182e-02,  7.6660e-02,\n",
      "        -1.7960e-02, -6.3248e-03, -2.1484e-02,  2.8000e-02,  8.2932e-03,\n",
      "        -1.1743e-01, -6.8909e-02,  5.4626e-02,  3.2654e-02, -1.6434e-02,\n",
      "         5.4993e-02,  4.6043e-03, -3.7098e-04, -3.2776e-02,  2.1393e-02,\n",
      "         3.5583e-02,  1.0292e-02, -5.3589e-02, -3.4924e-03,  2.3499e-02,\n",
      "        -2.6951e-03, -5.6953e-03,  2.6718e-02, -6.9771e-03, -2.0905e-02,\n",
      "         3.4027e-02, -9.0210e-02, -9.1476e-03, -4.9927e-02, -2.2339e-02,\n",
      "         6.8188e-04, -2.5391e-02, -2.3270e-02, -1.9852e-02,  3.0777e-02,\n",
      "        -5.1117e-03,  7.3051e-03, -5.3368e-03,  5.4871e-02,  1.5823e-02,\n",
      "         3.2227e-02,  2.3697e-02, -4.5654e-02, -1.5457e-02,  4.1595e-02,\n",
      "         9.7752e-04,  2.8019e-03,  4.0192e-02, -2.4841e-02,  7.9590e-02,\n",
      "        -2.5101e-02,  5.3024e-04, -4.7119e-02, -4.7577e-02,  6.3667e-03,\n",
      "        -3.1769e-02, -2.1683e-02,  1.5396e-02,  3.7292e-02,  4.8004e-02,\n",
      "        -3.4546e-02, -1.3123e-02,  3.6194e-02, -2.2430e-02, -5.8380e-02,\n",
      "        -2.4933e-02,  4.7394e-02,  1.6312e-02,  2.6245e-03, -7.7332e-02,\n",
      "        -2.3468e-02, -1.9646e-03, -3.1834e-03, -1.2825e-02,  1.8875e-02,\n",
      "         1.8950e-03,  6.4087e-02,  2.1362e-02, -1.2922e-03,  2.0355e-02,\n",
      "         3.1403e-02,  8.0338e-03, -4.3249e-04,  2.8763e-02, -5.0018e-02,\n",
      "        -5.1483e-02,  9.5337e-02, -1.9989e-02, -1.5732e-02, -8.1604e-02,\n",
      "        -7.8735e-02, -4.7638e-02, -1.8206e-03,  1.1978e-02,  1.9577e-02,\n",
      "         3.0231e-03,  1.1940e-02,  3.2288e-02,  6.4621e-03,  1.6968e-02,\n",
      "         7.6141e-03,  3.0930e-02, -1.9501e-02,  7.8278e-03, -5.6953e-03,\n",
      "         1.1082e-03, -4.3732e-02,  2.5986e-02, -5.0690e-02, -1.3771e-02,\n",
      "        -2.4548e-03, -2.1759e-02, -6.9332e-04,  3.9520e-02, -2.7313e-02,\n",
      "         5.0507e-02,  5.0598e-02, -1.7456e-02, -3.3661e-02, -3.1799e-02,\n",
      "        -3.7750e-02, -3.7231e-02, -2.9633e-02,  2.2552e-02,  1.5915e-02,\n",
      "        -5.9080e-04,  4.3945e-02, -5.9906e-02,  2.3376e-02,  9.2030e-04,\n",
      "         1.2947e-02,  1.2871e-02,  6.3293e-02, -1.8349e-03,  5.6335e-02,\n",
      "        -6.5308e-02,  3.1113e-02,  3.5309e-02,  2.4734e-02, -7.5745e-02,\n",
      "         1.6281e-02, -2.0123e-03, -3.4523e-03, -9.1614e-02,  6.5125e-02,\n",
      "        -1.5434e-02, -2.8782e-03, -2.7542e-02, -3.1830e-02, -9.8572e-03,\n",
      "         1.7120e-02,  3.1189e-02, -5.0087e-03, -5.7343e-02,  5.5618e-03,\n",
      "         1.3557e-02,  5.3062e-03, -3.7109e-02, -6.4209e-02,  2.0203e-02,\n",
      "         3.1235e-02,  3.4332e-02,  4.0253e-02,  4.2175e-02, -5.0201e-03,\n",
      "        -1.6006e-02,  5.6458e-03, -4.7760e-02,  2.2095e-02,  2.3544e-02,\n",
      "         1.3969e-02,  1.1131e-02,  9.3384e-03,  3.7556e-03, -2.0542e-03,\n",
      "         5.2881e-04, -1.2733e-02,  5.7297e-03, -3.2623e-02, -4.3060e-02,\n",
      "        -1.0727e-02, -6.7139e-02, -1.6510e-02, -1.4885e-02,  2.8915e-02,\n",
      "         1.7380e-02,  3.2063e-03,  7.4341e-02, -3.1464e-02,  8.9050e-02,\n",
      "         1.0948e-03,  9.2773e-03,  6.9031e-02,  3.4976e-04, -4.8370e-02,\n",
      "         2.9190e-02, -1.3466e-02,  4.0924e-02, -3.1494e-02, -1.2848e-02,\n",
      "         5.1788e-02, -5.2032e-02,  3.6125e-03,  1.3535e-02,  6.6185e-03,\n",
      "        -6.8130e-03,  5.0850e-03, -1.3763e-02,  5.0781e-02,  1.4450e-02,\n",
      "         1.0918e-02, -5.2155e-02, -2.9953e-02, -3.1647e-02, -5.9113e-02,\n",
      "        -6.4468e-03,  1.8036e-02, -3.3112e-02, -4.5090e-03,  1.0175e-01,\n",
      "         2.7267e-02,  3.5126e-02,  7.5607e-03, -8.8654e-03, -4.1809e-03,\n",
      "         6.7688e-02, -9.4177e-02, -3.1662e-03, -1.3741e-02,  6.9656e-03,\n",
      "         2.7802e-02,  4.1580e-03, -5.5580e-03, -5.5580e-03, -9.4604e-03,\n",
      "        -8.4000e-03,  5.5878e-02,  4.8004e-02, -1.1549e-03,  3.2928e-02,\n",
      "        -9.6283e-03,  1.0635e-02,  5.3955e-02, -1.4503e-02, -3.8696e-02,\n",
      "         2.4918e-02, -3.1143e-02, -7.6477e-02,  1.8387e-02,  7.3547e-02,\n",
      "        -1.0109e-02,  4.9973e-03,  6.2042e-02, -1.3557e-02,  1.6632e-02,\n",
      "        -1.8311e-02, -1.6022e-02,  2.2964e-02,  1.9318e-02,  2.0123e-03,\n",
      "        -1.0422e-02, -1.7517e-02, -1.4404e-02,  1.3947e-02,  5.6839e-03,\n",
      "        -7.8964e-03, -9.0271e-02,  1.5930e-02, -3.2867e-02,  9.2850e-03,\n",
      "        -1.8890e-02, -4.2839e-03, -4.3583e-04, -1.6388e-02, -2.5253e-02,\n",
      "        -5.1483e-02, -3.1090e-03,  3.9062e-02,  4.1840e-02, -5.0385e-02,\n",
      "        -1.6747e-03, -1.7059e-02, -1.3947e-02,  7.6477e-02, -7.6599e-02,\n",
      "         7.5150e-04,  3.5583e-02,  5.0781e-02, -3.5736e-02, -2.2736e-02,\n",
      "        -1.4679e-02, -6.3419e-04, -2.5253e-02,  3.7842e-02, -2.6443e-02,\n",
      "         9.1858e-02, -2.7313e-02,  7.5745e-02,  1.4771e-02,  1.5190e-02,\n",
      "         3.2562e-02, -1.0162e-02, -3.2997e-03, -1.2009e-02, -9.4910e-03,\n",
      "        -5.7098e-02, -2.1973e-02, -6.4575e-02, -2.2316e-03,  9.7885e-03,\n",
      "         4.0894e-02,  6.3477e-03, -3.2288e-02,  5.3070e-02,  8.9569e-03,\n",
      "         8.4763e-03, -1.8768e-02,  4.4189e-02,  2.0714e-03,  3.2940e-03,\n",
      "         6.4209e-02,  5.0598e-02, -1.5823e-02,  6.3538e-02, -2.1851e-02,\n",
      "         2.2984e-03, -1.0809e-01, -1.1520e-02,  4.4189e-02,  6.6185e-03,\n",
      "         1.0498e-02, -7.1564e-03, -7.1472e-02, -3.7506e-02,  3.2940e-03,\n",
      "        -1.3359e-02, -3.2020e-04,  1.7563e-02, -3.6102e-02,  1.1688e-02,\n",
      "        -5.1697e-02,  3.3386e-02, -6.8420e-02, -5.0201e-02,  6.9702e-02,\n",
      "         3.0090e-02,  1.5167e-02,  6.4697e-03, -5.7068e-03, -1.1780e-02,\n",
      "         1.7288e-02, -6.4125e-03, -8.3923e-03, -4.1718e-02, -8.3740e-02,\n",
      "         3.9001e-02,  1.5228e-02,  8.6365e-03, -3.4821e-02,  8.9645e-03,\n",
      "         2.2690e-02, -4.2725e-02, -4.5319e-02, -4.5380e-02,  9.8114e-03,\n",
      "        -2.2186e-02, -9.5642e-02,  7.3181e-02, -9.7513e-04, -2.2781e-02,\n",
      "         2.1194e-02, -4.1313e-03, -4.1504e-02,  3.2135e-02, -2.4002e-02,\n",
      "         9.3155e-03, -1.7792e-02,  3.0380e-02, -2.6352e-02, -4.9652e-02,\n",
      "        -9.1705e-03, -1.3725e-02, -2.4048e-02, -2.1324e-03,  2.7222e-02,\n",
      "         0.0000e+00,  1.6312e-02,  2.7542e-02, -6.9618e-03, -3.0518e-02,\n",
      "        -2.6398e-02, -1.0429e-02, -2.4071e-03,  2.2690e-02, -3.4637e-03,\n",
      "         8.3313e-03, -2.0146e-04, -1.6495e-02,  6.9504e-03,  4.5776e-03,\n",
      "        -1.0658e-02, -2.9053e-02,  3.9703e-02, -1.0704e-02,  2.3453e-02,\n",
      "         5.8533e-02, -2.3376e-02,  2.6215e-02,  2.1408e-02, -2.8687e-02,\n",
      "        -2.0721e-02,  4.1779e-02,  1.0941e-02,  2.2079e-02,  3.3020e-02,\n",
      "        -1.6846e-02, -2.1324e-03,  3.4363e-02,  5.0879e-04, -5.1422e-02,\n",
      "         1.0704e-02,  5.5962e-03, -1.3123e-02,  3.1250e-02,  2.7504e-03,\n",
      "         3.4576e-02,  9.4177e-02,  4.8553e-02,  1.6541e-02, -2.5421e-02,\n",
      "        -3.5286e-03,  1.0366e-03, -1.5976e-02,  2.9404e-02,  2.4094e-02,\n",
      "         2.8595e-02,  1.9424e-02,  3.8490e-03, -1.5602e-03,  2.9724e-02,\n",
      "        -4.9927e-02,  9.4986e-03, -1.3489e-02,  4.2694e-02, -8.4778e-02,\n",
      "         2.6016e-02, -1.1945e-01,  3.7415e-02,  1.2421e-02, -2.4475e-02,\n",
      "        -3.8643e-03,  4.9561e-02,  7.3730e-02,  9.6436e-03,  3.2715e-02,\n",
      "         4.0558e-02, -2.2644e-02,  4.6112e-02, -3.9612e-02,  2.5055e-02,\n",
      "         2.8000e-02, -2.2221e-03, -4.5891e-03,  4.1016e-02,  1.2256e-01,\n",
      "        -5.4962e-02,  2.6978e-02, -1.4206e-02, -1.3018e-04,  6.0120e-03,\n",
      "         3.9795e-02, -4.1084e-03,  3.2288e-02, -2.6794e-02, -6.8054e-03,\n",
      "        -6.4240e-03, -1.6495e-02,  2.5330e-02,  2.5162e-02,  2.5558e-02,\n",
      "        -2.0630e-02,  2.8305e-02, -4.9225e-02,  8.2016e-03,  1.5137e-02,\n",
      "        -8.4839e-03,  5.5603e-02,  4.1962e-03,  1.5602e-02,  6.1417e-03,\n",
      "         2.3422e-02,  1.9211e-02, -1.9165e-02,  4.9866e-02, -1.7517e-02,\n",
      "        -9.2983e-06, -2.0142e-02, -3.6316e-02, -9.7580e-03, -6.9946e-02,\n",
      "         1.1726e-02, -1.1650e-02,  2.1149e-02,  5.3978e-03,  3.4668e-02,\n",
      "        -5.2032e-02,  2.0233e-02, -3.7354e-02, -6.8726e-02,  3.6957e-02,\n",
      "        -4.8126e-02, -1.9440e-02, -1.8387e-02, -2.1912e-02,  9.3002e-03,\n",
      "        -4.8950e-02, -4.4769e-02,  1.7609e-02,  3.5763e-07, -1.6113e-02,\n",
      "        -1.5045e-02, -4.7119e-02, -4.0283e-02,  4.0070e-02,  1.7700e-02,\n",
      "        -1.9165e-02,  4.7302e-02,  5.5359e-02,  4.7455e-03, -4.6873e-04,\n",
      "         3.1494e-02, -3.6255e-02, -8.8501e-03, -6.6406e-02,  6.1722e-03,\n",
      "        -4.4800e-02, -5.8624e-02, -1.4137e-02, -1.6235e-02,  3.9612e-02,\n",
      "        -6.5552e-02, -2.9465e-02, -6.0577e-03, -1.3428e-02, -5.4138e-02,\n",
      "         3.2654e-02,  3.0731e-02, -4.0924e-02, -3.9886e-02,  4.3823e-02,\n",
      "        -2.2339e-02, -2.5986e-02,  2.2995e-02, -3.2005e-03,  2.4246e-02,\n",
      "         8.5754e-03,  3.2878e-04,  1.0567e-02,  4.3915e-02,  3.8300e-02,\n",
      "         5.5969e-02, -1.9592e-02,  2.7115e-02,  3.0640e-02,  1.5320e-01,\n",
      "         1.9119e-02, -6.3782e-02, -3.7811e-02,  3.9139e-03,  2.0126e-02,\n",
      "        -4.9400e-03,  2.5208e-02, -1.0635e-02,  3.0766e-03,  8.8120e-03,\n",
      "        -1.2558e-02, -1.2871e-02, -1.9623e-02,  1.0083e-01, -6.8970e-02,\n",
      "         7.1472e-02,  1.9236e-03,  3.6418e-05, -7.6485e-03, -5.0598e-02,\n",
      "         1.8433e-02,  0.0000e+00, -2.1927e-02,  5.0110e-02,  4.4891e-02,\n",
      "        -5.9891e-03,  4.6501e-03,  3.3173e-02, -2.8091e-02,  2.6581e-02,\n",
      "         4.8943e-03, -1.3031e-02,  2.2278e-03], dtype=torch.float16)\n",
      " Shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"IPU runtime: {runtime}\\n First embedding: {embeddings[0]}\\n Shape: {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353baa3c-39ce-4e6f-9500-d3cc3831c608",
   "metadata": {},
   "source": [
    "The embedding vector in its current state doesn't look particularly meaningful. The embeddings for a single sequence represent low-dimensional numerical representations of the word-level and sentence-level context for each token. These pre-trained embeddings can be used in applications like embedding retrieval for recommender systems, or semantic search for query-matching using cosine-similarity. Both of these use cases take advantage of the generated embeddings space, by performing a relative comparison of the user input sequence embeddings using some proximity metric.\n",
    "\n",
    "We'll use the open source `sentence_transformers` library which provides utilities for embeddings tasks to perform semantic search on a user query to retrieve the most similar sequences from the dataset to the query. This is a helpful utility for making, for example, more responsive FAQs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0341f-1ddf-4ddd-a224-663ca6c5d290",
   "metadata": {},
   "source": [
    "## Semantic search with E5 generated embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e889bd-47b4-4fc6-805f-deffe287b717",
   "metadata": {},
   "source": [
    "Using the `rotten_tomatoes` dataset, lets create a simple similarity search engine using `sentence_transformers` semantic search function, which uses cosine similarity to retrieve close-proximity sentences from a given set of embeddings to a given query. We have already generated embeddings for the dataset, so the next step is to do the same with a given query and perform the search.\n",
    "\n",
    "First, to process the query, we need to tokenize it and convert it to a single-batch input for the model. This has been wrapped into a simple function which tokenizes and prepares a dictionary of model inputs (`input_ids`, `attention_mask`, etc.,) to which we just need to pass a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3efe05fe-8e30-4d17-ade7-e92df76fd6ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_query(query: str):\n",
    "    t_query = tokenizer(\n",
    "            query,\n",
    "            max_length=max_seq_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    return {k: torch.as_tensor([t_query[k]]) for k in t_query}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001da157-186d-484e-abd8-b3373063deba",
   "metadata": {},
   "source": [
    "Next, to perform inference with a single input (i.e., effective batch size of 1) we re-instantiate the model by setting all device batching, replication and micro batch-size to 1 and re-compile the model. The change in batch size necessitates a recompilation, since the input shape to the model has been changed. We will follow the steps to initiate the model outlined earlier in the notebook, with the only change being setting the `get_ipu_config` function to have all batching turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a81edc13-236e-4577-bbf4-01904cc09777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph compilation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:51<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6932e-02,  3.1342e-02, -2.2217e-02, -5.3680e-02,  7.3013e-03,\n",
       "          5.1941e-02,  3.7811e-02, -2.4506e-02, -1.6937e-02,  2.7962e-03,\n",
       "          7.0374e-02,  7.4463e-02,  3.8574e-02, -4.4067e-02,  2.1652e-02,\n",
       "          7.5562e-02, -6.2752e-03,  2.0935e-02, -5.2185e-02, -5.7487e-03,\n",
       "         -4.4678e-02, -2.0340e-02,  5.6213e-02, -3.9101e-03, -3.6499e-02,\n",
       "         -3.6041e-02,  1.8204e-02, -2.0126e-02,  7.0381e-03,  2.8015e-02,\n",
       "         -3.0708e-03,  1.1101e-02,  6.1302e-03, -3.3051e-02,  1.3113e-06,\n",
       "          7.4310e-03,  7.8247e-02,  3.4912e-02, -4.5471e-02, -2.0790e-03,\n",
       "         -7.2250e-03,  6.4575e-02,  2.5543e-02,  6.8054e-02,  1.2589e-02,\n",
       "         -5.0306e-04, -4.1626e-02, -6.0699e-02, -1.7944e-02,  4.6277e-04,\n",
       "          1.2772e-02, -6.1981e-02, -2.6569e-03,  7.5035e-03,  1.2077e-02,\n",
       "         -4.1870e-02,  1.0063e-02, -3.3913e-03, -1.6098e-02,  4.7119e-02,\n",
       "          4.4373e-02,  6.0913e-02,  9.3307e-03, -3.3894e-03, -2.1500e-02,\n",
       "         -2.3468e-02,  3.4912e-02, -1.8173e-02, -2.9635e-04, -3.2318e-02,\n",
       "         -1.6129e-02, -2.6459e-02, -1.0386e-03,  2.5986e-02, -3.0685e-02,\n",
       "         -1.0779e-01,  2.9388e-02,  1.5312e-02,  9.9030e-03, -2.1118e-02,\n",
       "          1.1734e-02, -2.6779e-02, -2.3911e-02, -1.4524e-03,  4.4556e-02,\n",
       "          9.9869e-03, -2.7374e-02,  3.4294e-03,  7.4959e-03,  8.9539e-02,\n",
       "          4.4800e-02, -1.5732e-02, -4.6967e-02, -5.8258e-02, -1.5038e-02,\n",
       "         -2.2621e-03, -2.7065e-03, -1.6312e-02,  3.0334e-02, -6.9580e-02,\n",
       "         -2.7679e-02,  1.8600e-02,  3.4424e-02,  3.3813e-02,  7.6256e-03,\n",
       "         -1.3359e-02,  7.6904e-02, -4.3091e-02, -3.1776e-03,  2.9800e-02,\n",
       "         -6.7566e-02, -1.5472e-02, -3.0289e-02,  3.5370e-02,  4.9866e-02,\n",
       "          7.1960e-02, -4.7302e-02, -1.7059e-02,  5.3772e-02,  3.8849e-02,\n",
       "         -2.1439e-03, -3.5400e-02, -2.9877e-02,  4.7821e-02,  7.4097e-02,\n",
       "         -4.5349e-02, -1.4786e-02, -1.4053e-02, -1.2688e-02, -9.8022e-02,\n",
       "         -5.8591e-05, -1.8066e-02, -3.4851e-02,  4.8187e-02,  1.5320e-02,\n",
       "         -2.1469e-02, -1.9333e-02, -5.6671e-02, -1.7944e-02, -5.7312e-02,\n",
       "          5.6061e-02, -3.3569e-02, -6.9702e-02, -7.1655e-02, -3.3813e-02,\n",
       "          1.5915e-02,  4.2572e-03,  3.1189e-02, -2.5349e-03, -2.0599e-02,\n",
       "         -2.3346e-03,  5.2063e-02,  9.7290e-02, -3.2902e-04,  1.7044e-02,\n",
       "          2.5970e-02,  9.1064e-02,  4.8798e-02, -3.9864e-03,  3.5706e-03,\n",
       "          3.1952e-02, -1.8950e-03,  2.0416e-02,  3.6926e-03, -2.8320e-02,\n",
       "          1.2474e-02, -4.0550e-03,  2.7130e-02,  3.5114e-03,  1.8204e-02,\n",
       "         -1.9379e-02, -5.3375e-02,  2.6455e-03,  8.5876e-02, -2.2202e-02,\n",
       "         -3.0365e-03,  5.1971e-02,  1.4114e-02,  4.4556e-02,  7.8735e-03,\n",
       "         -4.6021e-02,  1.9669e-02, -2.8961e-02,  8.2779e-03, -3.6163e-02,\n",
       "         -2.0645e-02, -1.3809e-02, -1.0262e-02, -1.2901e-02, -3.7994e-02,\n",
       "          7.6866e-04, -5.1928e-04, -2.5726e-02,  1.6983e-02,  1.6525e-02,\n",
       "         -4.2686e-03, -1.6281e-02, -3.0193e-03, -8.2474e-03, -5.1453e-02,\n",
       "         -4.5738e-03, -2.0767e-02, -9.9411e-03, -9.9850e-04, -1.3924e-02,\n",
       "          4.0558e-02,  6.3293e-02,  3.9337e-02,  2.4643e-02, -7.1899e-02,\n",
       "          1.2444e-02, -1.6006e-02,  7.3486e-02,  3.7598e-02,  2.1591e-03,\n",
       "          3.1006e-02, -1.2947e-02,  2.0538e-02,  2.0386e-02, -3.4424e-02,\n",
       "         -3.0991e-02,  1.4572e-02,  1.7059e-02,  5.0507e-02, -1.0506e-02,\n",
       "         -1.1951e-01,  1.6144e-02,  8.3466e-03, -1.1528e-02, -3.4485e-02,\n",
       "         -5.5054e-02, -2.2202e-02,  2.4414e-02,  1.1284e-02, -2.1729e-02,\n",
       "         -2.8656e-02, -9.5291e-03, -6.3843e-02, -4.3060e-02, -4.8950e-02,\n",
       "         -5.8777e-02, -4.5746e-02, -4.0253e-02,  4.2206e-02,  1.0742e-02,\n",
       "          5.4749e-02,  7.4539e-03,  2.3712e-02,  3.1281e-02, -2.0218e-02,\n",
       "          5.7526e-03, -4.9324e-03, -1.0101e-02, -7.9346e-03,  4.2610e-03,\n",
       "          4.3823e-02,  4.5380e-02,  5.3192e-02, -2.2697e-03, -4.4403e-02,\n",
       "         -5.5206e-02,  1.0147e-02, -8.2245e-03,  1.4465e-02,  5.2795e-02,\n",
       "          8.0261e-02, -1.0315e-01, -4.3121e-02,  3.1433e-02, -2.1255e-02,\n",
       "         -3.0251e-03, -7.2250e-03,  2.2552e-02,  8.2779e-03, -3.5950e-02,\n",
       "          2.1225e-02,  1.1139e-02,  2.6474e-02,  2.1057e-02, -2.6215e-02,\n",
       "         -3.0762e-02, -2.3254e-02,  9.4299e-03, -4.5959e-02,  5.9082e-02,\n",
       "          4.1077e-02,  3.9215e-02,  1.6312e-02, -6.6956e-02,  2.6031e-02,\n",
       "          4.4281e-02,  1.0033e-02,  3.2593e-02,  6.0425e-03,  3.5217e-02,\n",
       "          2.7557e-02,  2.8809e-02,  7.5684e-03, -2.1561e-02, -4.6356e-02,\n",
       "          1.0567e-02,  9.7504e-03, -5.5450e-02, -4.1168e-02,  3.4302e-02,\n",
       "         -6.0303e-02,  3.7720e-02, -4.0192e-02, -4.3732e-02,  3.3722e-02,\n",
       "          4.7211e-02, -7.3853e-03, -1.1986e-02, -4.7760e-03, -3.9902e-03,\n",
       "         -6.9397e-02,  3.5675e-02, -2.8046e-02, -3.4637e-02, -3.9825e-02,\n",
       "          4.5135e-02, -5.6030e-02,  2.7679e-02,  3.0279e-04, -1.1650e-02,\n",
       "          2.5177e-02,  4.9377e-02,  8.1635e-03,  2.5986e-02,  3.1929e-03,\n",
       "         -4.4312e-02, -2.4521e-02, -3.0563e-02,  5.1086e-02,  4.1870e-02,\n",
       "          1.3702e-02,  1.0872e-03,  2.1790e-02, -1.2291e-02, -3.7251e-03,\n",
       "          2.4857e-02, -4.0924e-02, -3.7292e-02,  1.2779e-02, -2.9663e-02,\n",
       "         -3.6407e-02,  5.6763e-02,  4.5013e-03,  7.7553e-03, -2.9312e-02,\n",
       "          6.0272e-02, -2.8015e-02,  1.9669e-02, -5.0751e-02, -2.6459e-02,\n",
       "         -4.5258e-02,  6.4278e-04, -3.0716e-02, -2.8870e-02,  5.4535e-02,\n",
       "          2.3834e-02, -1.7303e-02,  7.3975e-02,  2.0950e-02, -4.0222e-02,\n",
       "         -4.3427e-02,  2.4200e-02,  5.1208e-02, -3.5706e-02,  3.5095e-02,\n",
       "          8.9264e-03, -1.0933e-02, -5.2460e-02, -4.5044e-02, -1.0246e-02,\n",
       "          1.9638e-02,  1.2344e-02,  5.8655e-02,  3.8208e-02, -1.4816e-02,\n",
       "          1.2894e-02, -2.2217e-02, -2.3224e-02,  2.9251e-02,  3.6072e-02,\n",
       "         -1.9989e-02,  5.6335e-02,  1.2917e-02,  1.0437e-02,  1.6525e-02,\n",
       "         -2.5406e-02,  5.8380e-02, -4.8309e-02, -6.0234e-03, -2.1729e-02,\n",
       "         -2.9480e-02, -5.5206e-02, -6.3286e-03,  4.5715e-02,  4.2236e-02,\n",
       "         -4.1008e-03,  2.0126e-02,  1.9302e-02,  4.9500e-02,  1.1566e-02,\n",
       "          1.0017e-02,  4.8309e-02,  3.2210e-04,  1.5190e-02, -1.4820e-03,\n",
       "          3.9276e-02, -5.3925e-02,  2.6276e-02, -4.1138e-02,  5.0934e-02,\n",
       "          4.0558e-02, -1.6785e-02, -7.9651e-03, -4.5593e-02,  1.2810e-02,\n",
       "          1.4908e-02,  2.3010e-02, -2.9388e-02,  1.4679e-02, -4.3549e-02,\n",
       "          5.1537e-03,  9.3536e-03, -1.6678e-02, -4.6234e-02, -4.3213e-02,\n",
       "         -8.1558e-03, -2.6749e-02, -1.1467e-02, -1.9531e-03, -9.4177e-02,\n",
       "         -2.6382e-02, -4.6600e-02, -5.8258e-02,  1.5022e-02,  4.7607e-02,\n",
       "          1.9653e-02, -2.5082e-03,  5.0323e-02, -4.7577e-02, -7.9041e-02,\n",
       "          1.9035e-03,  4.6600e-02, -4.4525e-02,  1.7762e-04,  5.9631e-02,\n",
       "          3.2825e-03, -9.9468e-04, -9.4910e-03,  1.6693e-02,  2.5955e-02,\n",
       "          2.8572e-03,  1.1310e-01, -7.4768e-02, -1.5076e-02, -3.7117e-03,\n",
       "         -1.5442e-02,  6.2904e-03,  4.2969e-02,  5.9013e-03, -1.2794e-02,\n",
       "          2.8763e-02, -1.4359e-02,  8.3847e-03,  6.3232e-02,  1.9318e-02,\n",
       "         -5.4108e-02,  4.9316e-02, -1.9333e-02, -1.5053e-02, -2.2552e-02,\n",
       "          2.6642e-02, -3.4973e-02, -3.2593e-02, -7.1960e-02,  5.9776e-03,\n",
       "          3.9001e-02,  4.8714e-03,  1.2642e-02,  4.6234e-02,  1.4160e-02,\n",
       "         -1.1925e-02,  7.8735e-02, -1.1192e-02, -3.5156e-02,  2.1179e-02,\n",
       "         -3.1494e-02, -4.3304e-02, -1.3565e-02,  5.9753e-02, -3.5767e-02,\n",
       "          3.9154e-02,  1.8204e-02, -5.9357e-02, -1.9791e-02, -1.8129e-03,\n",
       "          3.5034e-02,  4.7974e-02, -3.6743e-02,  5.4871e-02,  5.7983e-02,\n",
       "         -6.2683e-02, -4.1618e-03, -3.7537e-02,  6.6414e-03,  5.5481e-02,\n",
       "          2.6642e-02, -5.4932e-02,  3.7781e-02,  2.7420e-02, -1.3931e-02,\n",
       "          1.7029e-02,  7.2327e-03,  3.1830e-02,  2.3376e-02,  2.4170e-02,\n",
       "         -9.8495e-03, -2.1011e-02,  1.5930e-02, -3.9886e-02, -2.0889e-02,\n",
       "         -7.7271e-02,  1.0086e-02,  2.7084e-02, -5.2795e-02,  5.9143e-02,\n",
       "         -5.1422e-02, -4.0405e-02,  1.5312e-02, -4.4250e-03, -1.2375e-02,\n",
       "         -1.1559e-02, -3.0624e-02, -4.5227e-02,  2.4261e-02,  1.8524e-02,\n",
       "          2.2812e-02,  6.0425e-03, -1.2825e-02,  5.1788e-02,  3.8849e-02,\n",
       "          3.1464e-02,  4.6814e-02,  1.0994e-02,  3.5034e-02, -3.0762e-02,\n",
       "          6.5346e-03,  6.5796e-02,  1.1353e-01,  9.8953e-03,  1.0626e-01,\n",
       "          0.0000e+00, -4.4556e-02,  2.1790e-02, -8.0643e-03,  2.8595e-02,\n",
       "          2.8320e-02, -2.6199e-02, -2.0416e-02,  1.8402e-02,  6.7566e-02,\n",
       "          4.6959e-03,  7.6103e-03, -2.7603e-02,  1.9180e-02, -1.0358e-01,\n",
       "          1.2286e-01,  2.7771e-02,  1.1963e-02, -4.0344e-02, -6.1554e-02,\n",
       "          1.0109e-02,  1.1314e-02,  2.4170e-02, -3.4485e-02,  3.6407e-02,\n",
       "          7.4577e-04,  4.0779e-03, -4.8485e-03, -1.3290e-02, -1.4791e-03,\n",
       "         -1.8326e-02,  2.2690e-02, -8.2474e-03, -2.7008e-02, -7.5569e-03,\n",
       "         -3.7415e-02,  7.4921e-03,  3.3975e-04, -2.5803e-02,  7.4196e-03,\n",
       "          4.3640e-03, -2.2949e-02, -8.3847e-03,  1.2016e-02, -2.2400e-02,\n",
       "          9.2745e-04,  4.8141e-03, -1.6571e-02,  3.1738e-02,  8.7891e-03,\n",
       "         -4.8523e-02, -3.3417e-02, -8.7023e-05,  4.3373e-03, -1.5106e-02,\n",
       "         -5.6885e-02, -8.1558e-03, -4.5128e-03, -1.9791e-02, -3.2776e-02,\n",
       "          1.9089e-02, -1.3779e-02,  3.8090e-03,  1.1261e-02, -6.4026e-02,\n",
       "          3.7746e-03, -2.5299e-02, -1.6708e-02, -4.0497e-02, -5.0690e-02,\n",
       "         -2.8931e-02,  4.8065e-02, -5.5908e-02,  2.0935e-02,  2.4353e-02,\n",
       "          5.0110e-02, -7.6538e-02, -4.9957e-02, -5.6458e-02,  5.2582e-02,\n",
       "         -8.7814e-03, -1.1589e-02, -1.3962e-02, -5.4741e-03, -8.8196e-03,\n",
       "         -4.9255e-02,  3.1525e-02, -3.4370e-03,  9.5367e-03, -1.5358e-02,\n",
       "          2.1225e-02,  3.6316e-02, -2.1500e-02,  4.1046e-02, -1.6907e-02,\n",
       "          5.2528e-03,  1.7975e-02, -2.0844e-02, -2.4292e-02,  2.9572e-02,\n",
       "          3.0701e-02, -3.1528e-03,  3.5767e-02,  6.7253e-03, -2.7435e-02,\n",
       "          3.8513e-02,  2.8214e-02, -2.5511e-05, -5.8060e-03, -3.4454e-02,\n",
       "         -4.4918e-04, -2.0050e-02, -1.1703e-02,  1.9684e-02, -3.1586e-02,\n",
       "         -1.1139e-02,  1.6846e-02, -1.7700e-02, -3.6560e-02, -2.0615e-02,\n",
       "         -1.3237e-02, -5.4230e-02,  4.4434e-02,  1.1401e-01,  6.2927e-02,\n",
       "         -5.0598e-02,  3.3783e-02,  1.9562e-02,  4.5395e-03,  4.9591e-02,\n",
       "         -7.9107e-04, -6.7749e-02,  4.7943e-02,  2.3842e-07, -1.0437e-02,\n",
       "          1.4969e-02, -4.5288e-02,  6.2561e-02, -2.7237e-02,  2.0447e-02,\n",
       "          5.2757e-03,  3.9795e-02, -1.7960e-02,  4.8035e-02, -4.5044e-02,\n",
       "         -1.6312e-02,  2.7115e-02, -4.3488e-03,  2.7496e-02, -1.9623e-02,\n",
       "          1.3069e-02,  5.0629e-02, -7.4959e-03, -2.0782e-02, -6.0333e-02,\n",
       "         -2.7405e-02, -1.5173e-03,  2.1896e-02, -4.0619e-02,  3.5858e-02,\n",
       "         -3.1525e-02,  5.0507e-02,  4.7760e-03,  4.9530e-02, -3.2349e-02,\n",
       "          4.0070e-02,  8.8730e-03,  6.8712e-04, -4.3549e-02, -7.0374e-02,\n",
       "          4.9835e-02,  3.3783e-02,  2.0645e-02,  3.7842e-02,  4.6692e-02,\n",
       "         -3.3417e-02, -3.7354e-02,  5.5176e-02, -1.8646e-02, -2.7267e-02,\n",
       "          3.0167e-02, -3.0685e-02,  2.9785e-02,  5.1918e-03, -1.1292e-02,\n",
       "          4.8920e-02,  3.8513e-02,  9.9564e-03,  1.9684e-02,  1.9745e-02,\n",
       "          1.1322e-02,  2.0370e-02,  4.4403e-03,  3.9581e-02, -3.3234e-02,\n",
       "         -6.2805e-02,  3.9093e-02, -1.4038e-02,  2.5711e-02, -5.2834e-03,\n",
       "         -1.8890e-02,  0.0000e+00,  2.1774e-02,  6.9733e-03,  1.5732e-02,\n",
       "          3.0804e-04, -5.0476e-02, -2.3621e-02, -6.2927e-02, -4.8187e-02,\n",
       "          4.3213e-02, -6.9214e-02, -6.0760e-02]], dtype=torch.float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipu_config = get_ipu_config(model_config, n_ipu, model_ipu=1, device_iterations=1, replication_factor=1, random_seed=random_seed)\n",
    "\n",
    "inf_model = IPUEmbeddingsModel(\n",
    "    model_name = model_name,\n",
    "    model_config = model_config,\n",
    "    ipu_config = ipu_config\n",
    ")\n",
    "\n",
    "inf_model = poptorch.inferenceModel(inf_model, ipu_config.to_options(for_inference=True))\n",
    "\n",
    "inf_model(**prepare_query(\"Running once to compile\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a9655-f6c4-438b-845d-0bf9c954e8dd",
   "metadata": {},
   "source": [
    "Finally, we can use the model to embed a single query, and perform a semantic search across the full dataset embeddings to retrieve highly relevant reviews to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fccb8f74-3bc0-41a6-afc0-0d87d3cfd5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEARCH QUERY: Strongly disliked this action movie\n",
      "\n",
      " Result (rank 1) | Score: 0.761756420135498 | Text: it's a bad action movie because there's no rooting interest and the spectacle is grotesque and boring . \n",
      "\n",
      " Result (rank 2) | Score: 0.6813229322433472 | Text: i hate this movie \n",
      "\n",
      " Result (rank 3) | Score: 0.6623662710189819 | Text: features nonsensical and laughable plotting , wooden performances , ineptly directed action sequences and some of the worst dialogue in recent memory . \n",
      "\n",
      " Result (rank 4) | Score: 0.6618168950080872 | Text: 'this movie sucks . ' \n",
      "\n",
      " Result (rank 5) | Score: 0.6547254323959351 | Text: it is a comedy that's not very funny and an action movie that is not very thrilling ( and an uneasy alliance , at that ) . \n",
      "\n",
      " Result (rank 6) | Score: 0.6510480046272278 | Text: the worst film of the year . \n",
      "\n",
      " Result (rank 7) | Score: 0.6449141502380371 | Text: the acting is amateurish , the cinematography is atrocious , the direction is clumsy , the writing is insipid and the violence is at once luridly graphic and laughably unconvincing . \n",
      "\n",
      " Result (rank 8) | Score: 0.6420773863792419 | Text: it's another stale , kill-by-numbers flick , complete with blade-thin characters and terrible , pun-laden dialogue . \n",
      "\n",
      " Result (rank 9) | Score: 0.6315654516220093 | Text: doesn't deliver a great story , nor is the action as gripping as in past seagal films . \n",
      "\n",
      " Result (rank 10) | Score: 0.6296806335449219 | Text: despite the fact that this film wasn't as bad as i thought it was going to be , it's still not a good movie \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "query = \"Strongly disliked this action movie\"\n",
    "\n",
    "query_embeddings = inf_model(**prepare_query(query))\n",
    "hits = semantic_search(query_embeddings.float(), embeddings.float(), top_k=10)\n",
    "\n",
    "print(f\"\\n SEARCH QUERY: {query}\")\n",
    "for n, res in enumerate(hits[0]):\n",
    "    print(f\"\\n Result (rank {n+1}) | Score: {res['score']} | Text: {dataset['train']['text'][res['corpus_id']]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d439ae-5902-47d5-9ff3-c0bef5b22aa9",
   "metadata": {},
   "source": [
    "From the results, the pretrained embeddings appear to perform quite well on an unseen dataset without any fine-tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
