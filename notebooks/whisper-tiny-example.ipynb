{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b804343",
   "metadata": {},
   "source": [
    "# Whisper-tiny on IPU\n",
    "\n",
    "This notebook demonstrates inference with Whisper-tiny on IPU using FP16.    \n",
    "The present version of the IPU Whisper implementation runs the encoder and the decoder on IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2023 Graphcore Ltd. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "\"\"\" Run inference on a ðŸ¤— Whisper model \"\"\"\n",
    "\n",
    "from optimum.utils import logging\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import poptorch\n",
    "from optimum.graphcore import IPUConfig, IPUTrainer,IPUTrainingArguments\n",
    "from optimum.graphcore.modeling_utils import to_pipelined\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c672ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class IPUWhisperConf:\n",
    "    \"\"\"A data class to collect IPU-related config parameters\"\"\"\n",
    "    model_spec: str\n",
    "    ipus_per_replica: int\n",
    "    pod_type: str\n",
    "\n",
    "ipu_whisper = {\n",
    "    \"tiny\": IPUWhisperConf(model_spec='openai/whisper-tiny.en', ipus_per_replica=2, pod_type=\"pod4\"),\n",
    "    # Larger sizes will become available in due course\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"tiny\"\n",
    "iwc = ipu_whisper[model_size]\n",
    "max_length = 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate processor and model\n",
    "processor = WhisperProcessor.from_pretrained(iwc.model_spec)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(iwc.model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bef594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dummy dataset and read soundfiles\n",
    "test_idx = 4\n",
    "\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "input_features = processor(ds[test_idx][\"audio\"][\"array\"], \n",
    "                           return_tensors=\"pt\",\n",
    "                           sampling_rate=ds[test_idx]['audio']['sampling_rate']).input_features.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", iwc.pod_type)\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/whisper_exe_cache/\") + \"whisper_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"PVTI_OPTIONS\"]=r'{\"enable\":\"true\", \"directory\":\"/localdata/paolot/profiles/minimal\"}'\n",
    "# os.environ[\"POPLAR_ENGINE_OPTIONS\"] = f'{{\"autoReport.all\":\"true\", \"debug.allowOutOfMemory\": \"true\", \"autoReport.directory\":\"/localdata/paolot/profiles/no-pipeline-30\"}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_config = IPUConfig(executable_cache_dir=executable_cache_dir, ipus_per_replica=iwc.ipus_per_replica, matmul_proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1073fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelined_model = to_pipelined(model, ipu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca66754",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelined_model = pipelined_model.parallelize(for_generation=True).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17947b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = pipelined_model.generate(input_features, max_length=max_length, min_length=3)\n",
    "transcription = processor.batch_decode(sample_output, skip_special_tokens=False)[0]\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7dc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for _ in range(100):\n",
    "    sample_output = pipelined_model.generate(input_features, max_length=max_length, min_length=3)\n",
    "    transcription = processor.batch_decode(sample_output, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743078a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
