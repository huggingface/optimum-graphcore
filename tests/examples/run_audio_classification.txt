30,38c30,33
< from transformers import (
<     AutoConfig,
<     AutoFeatureExtractor,
<     AutoModelForAudioClassification,
<     HfArgumentParser,
<     Trainer,
<     TrainingArguments,
<     set_seed,
< )
---
> from optimum.graphcore import IPUConfig, IPUTrainer
> from optimum.graphcore import IPUTrainingArguments as TrainingArguments
> from optimum.graphcore.utils import check_min_version
> from transformers import AutoConfig, AutoFeatureExtractor, AutoModelForAudioClassification, HfArgumentParser, set_seed
40c35,36
< from transformers.utils import check_min_version, send_example_telemetry
---
> from transformers.utils import check_min_version as tf_check_min_version
> from transformers.utils import send_example_telemetry
47c43,46
< check_min_version("4.20.0.dev0")
---
> tf_check_min_version("4.19.0")
> 
> # Will error if the minimal version of Optimum Graphcore is not installed. Remove at your own risks.
> check_min_version("0.2.4.dev")
218,221d216
<     logger.warning(
<         f"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu} "
<         + f"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}"
<     )
287,308d281
<     def train_transforms(batch):
<         """Apply train_transforms across a batch."""
<         output_batch = {"input_values": []}
<         for audio in batch[data_args.audio_column_name]:
<             wav = random_subsample(
<                 audio["array"], max_length=data_args.max_length_seconds, sample_rate=feature_extractor.sampling_rate
<             )
<             output_batch["input_values"].append(wav)
<         output_batch["labels"] = [label for label in batch[data_args.label_column_name]]
< 
<         return output_batch
< 
<     def val_transforms(batch):
<         """Apply val_transforms across a batch."""
<         output_batch = {"input_values": []}
<         for audio in batch[data_args.audio_column_name]:
<             wav = audio["array"]
<             output_batch["input_values"].append(wav)
<         output_batch["labels"] = [label for label in batch[data_args.label_column_name]]
< 
<         return output_batch
< 
336a310,321
> 
>     # Disable these features that can't run on IPU yet
>     # TODO handle this properly
>     config.layerdrop = 0.0
>     config.mask_time_prob = 0.0
> 
>     ipu_config = IPUConfig.from_pretrained(
>         training_args.ipu_config_name if training_args.ipu_config_name else model_args.model_name_or_path,
>         cache_dir=model_args.cache_dir,
>         revision=model_args.model_revision,
>         use_auth_token=True if model_args.use_auth_token else None,
>     )
344c329,330
<         ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,
---
>         # TODO: enable this when requiring transformers == 4.20.0
>         # ignore_mismatched_sizes=model_args.ignore_mismatched_sizes,
350a337,354
>     def preprocess_function(examples):
>         audio = examples[data_args.audio_column_name]
>         subsampled_audio = random_subsample(
>             audio["array"], max_length=data_args.max_length_seconds, sample_rate=feature_extractor.sampling_rate
>         )
>         max_length = int(round(feature_extractor.sampling_rate * data_args.max_length_seconds))
>         inputs = feature_extractor(
>             subsampled_audio,
>             max_length=max_length,
>             sampling_rate=feature_extractor.sampling_rate,
>             padding="max_length",
>         )
>         examples["input_values"] = inputs["input_values"][0]
>         if not training_args.fp32:
>             examples["input_values"] = examples["input_values"].astype(np.float16)
>         examples["labels"] = examples[data_args.label_column_name]
>         return examples
> 
357c361,363
<         raw_datasets["train"].set_transform(train_transforms, output_all_columns=False)
---
>         raw_datasets["train"] = raw_datasets["train"].map(
>             preprocess_function, remove_columns=raw_datasets["train"].column_names
>         )
365c371,373
<         raw_datasets["eval"].set_transform(val_transforms, output_all_columns=False)
---
>         raw_datasets["eval"] = raw_datasets["eval"].map(
>             preprocess_function, remove_columns=raw_datasets["eval"].column_names
>         )
368c376
<     trainer = Trainer(
---
>     trainer = IPUTrainer(
369a378
>         ipu_config=ipu_config,
